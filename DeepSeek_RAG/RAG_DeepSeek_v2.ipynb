{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/claudio1975/Medium-blog/blob/master/DeepSeek_RAG/RAG_DeepSeek_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kih21u1tyr-I"
      },
      "source": [
        "# Naive RAG with DeepSeek and LangChain\n",
        "\n",
        "This notebook shows an easy RAG (Retrieval Augmented Generation) with DeepSeek model from Hugging Face [`deepseek-ai/DeepSeek-R1`](https://huggingface.co/deepseek-ai/DeepSeek-R1), and LangChain.\n",
        "\n",
        "\n",
        "**RAG process**\n",
        "\n",
        "The RAG (Retrieval-Augmented Generation) system combines a retrieval system with an LLM. The system first retrieves relevant documents from a corpus using a vector database, then uses an LLM hosted in Hugging Face to generate answers based on the retrieved documents.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prepare Workspace"
      ],
      "metadata": {
        "id": "KiCZPiJXcbTX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lC9frDOlyi38"
      },
      "outputs": [],
      "source": [
        "!pip install -q torch transformers sentence-transformers faiss-cpu pypdf &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-huggingface &>/dev/null"
      ],
      "metadata": {
        "id": "MC98Ot4o4UuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W5HhMZ2c-NfU"
      },
      "outputs": [],
      "source": [
        "!pip install -q langchain langchain-community &> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import langchain as lc\n",
        "from langchain import LLMMathChain\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain.schema import Document\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from transformers import pipeline\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_huggingface import HuggingFacePipeline\n"
      ],
      "metadata": {
        "id": "7f6wiKa43B-2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8po01vMWzXL"
      },
      "source": [
        "## Upload the data\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load content from local PDFs\n",
        "loader = PyPDFLoader(\"./2501.12948v1.pdf\")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "CKBP8kzo3OU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the document:\n",
        "Document(page_content=\"DeepSeek-R1:Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.\",\n",
        "         metadata={\n",
        "             'document_id' : '2501.12948v1',\n",
        "             'document_source' : \"ArXiv\",\n",
        "             'document_create_time' : \"2025\"\n",
        "         })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eG1tC4Uf3O4E",
        "outputId": "3a04fe9e-e98f-42d3-d637-530151710d99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'document_id': '2501.12948v1', 'document_source': 'ArXiv', 'document_create_time': '2025'}, page_content='DeepSeek-R1:Incentivizing Reasoning Capability in LLMs via Reinforcement Learning.')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nPage Content: \", docs[0].page_content)\n",
        "print(\"\\nMeta Data: \", docs[0].metadata)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pPicF82I3cJj",
        "outputId": "e3dc5168-0648-4dfd-826e-c6d2042aa3cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Page Content:  DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\n",
            "Reinforcement Learning\n",
            "DeepSeek-AI\n",
            "research@deepseek.com\n",
            "Abstract\n",
            "We introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\n",
            "DeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-\n",
            "vised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\n",
            "Through RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing\n",
            "reasoning behaviors. However, it encounters challenges such as poor readability, and language\n",
            "mixing. To address these issues and further enhance reasoning performance, we introduce\n",
            "DeepSeek-R1, which incorporates multi-stage training and cold-start data before RL. DeepSeek-\n",
            "R1 achieves performance comparable to OpenAI-o1-1217 on reasoning tasks. To support the\n",
            "research community, we open-source DeepSeek-R1-Zero, DeepSeek-R1, and six dense models\n",
            "(1.5B, 7B, 8B, 14B, 32B, 70B) distilled from DeepSeek-R1 based on Qwen and Llama.\n",
            "AIME 2024\n",
            "(Pass@1)\n",
            "Codeforces\n",
            "(Percentile)\n",
            "GPQA Diamond\n",
            "(Pass@1)\n",
            "MATH-500\n",
            "(Pass@1)\n",
            "MMLU\n",
            "(Pass@1)\n",
            "SWE-bench Verified\n",
            "(Resolved)\n",
            "0\n",
            "20\n",
            "40\n",
            "60\n",
            "80\n",
            "100Accuracy / Percentile (%)\n",
            "79.8\n",
            "96.3\n",
            "71.5\n",
            "97.3\n",
            "90.8\n",
            "49.2\n",
            "79.2\n",
            "96.6\n",
            "75.7\n",
            "96.4\n",
            "91.8\n",
            "48.9\n",
            "72.6\n",
            "90.6\n",
            "62.1\n",
            "94.3\n",
            "87.4\n",
            "36.8\n",
            "63.6\n",
            "93.4\n",
            "60.0\n",
            "90.0\n",
            "85.2\n",
            "41.6\n",
            "39.2\n",
            "58.7 59.1\n",
            "90.2\n",
            "88.5\n",
            "42.0\n",
            "DeepSeek-R1 OpenAI-o1-1217 DeepSeek-R1-32B OpenAI-o1-mini DeepSeek-V3\n",
            "Figure 1 |Benchmark performance of DeepSeek-R1.\n",
            "arXiv:2501.12948v1  [cs.CL]  22 Jan 2025\n",
            "\n",
            "Meta Data:  {'source': './2501.12948v1.pdf', 'page': 0, 'page_label': '1'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OmsXOf59Pmm-"
      },
      "outputs": [],
      "source": [
        "splitter = RecursiveCharacterTextSplitter(chunk_size=512, chunk_overlap=30)\n",
        "chunked_docs = splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"PDF Splited by Chunks - You have {0} number of chunks.\".format(len(docs)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9WeouS53tbA",
        "outputId": "4908bbf7-96a6-4631-e896-80d2b9160b40"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PDF Splited by Chunks - You have 22 number of chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAt_zPVlXOn7"
      },
      "source": [
        "## Embeddings + Retriever"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mvat6JQl4yp"
      },
      "source": [
        "For embeddings I use the `HuggingFaceEmbeddings` and the [`BAAI/bge-base-en-v1.5`](https://huggingface.co/BAAI/bge-base-en-v1.5) embeddings model.\n",
        "\n",
        "To create the vector database, I use `FAISS`, a library developed by Facebook AI. This library offers efficient similarity search and clustering of dense vectors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ixmCdRzBQ5gu"
      },
      "outputs": [],
      "source": [
        "db = FAISS.from_documents(chunked_docs,\n",
        "                          HuggingFaceEmbeddings(model_name='BAAI/bge-base-en-v1.5'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mBTreCQ9noHK"
      },
      "outputs": [],
      "source": [
        "retriever = db.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={'k': 3}\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzQxx0HkXVFU"
      },
      "source": [
        "## Load the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L-ggaa763VRo"
      },
      "outputs": [],
      "source": [
        "model_name = \"deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B\"\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVNRJALyXYHG"
      },
      "source": [
        "## Setup the LLM chain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUUNneJ1smhl"
      },
      "source": [
        "First, I create a text_generation pipeline using the loaded model and its tokenizer.\n",
        "\n",
        "Next, I create a prompt template.\n",
        "\n",
        "then, I combine the `llm_chain` with the retriever to create a RAG chain."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Pipeline for text generation\n",
        "text_generation_pipeline = pipeline(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    task=\"text-generation\",\n",
        "    temperature=0.2,\n",
        "    do_sample=True,\n",
        "    repetition_penalty=1.1,\n",
        "    return_full_text=True,\n",
        "    max_new_tokens=500,\n",
        ")\n",
        "\n",
        "llm = HuggingFacePipeline(pipeline=text_generation_pipeline)\n",
        "\n",
        "# Prompt template to match desired output format\n",
        "prompt_template = \"\"\"\n",
        "You are a professional AI researcher, give an help in study. Use the following context to answer the question using information provided by the paper:\n",
        "\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"context\", \"question\"],\n",
        "    template=prompt_template,\n",
        ")\n",
        "\n",
        "llm_chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "\n",
        "rag_chain = (\n",
        "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
        "    | llm_chain\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZjxG5zYVhlD",
        "outputId": "9942ef09-9e94-4d3f-ab42-a8403befc2e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Questions"
      ],
      "metadata": {
        "id": "eqqHajSXVtkN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are the advantages of using reinforcement learning directly on a base model, as demonstrated by DeepSeek-R1-Zero?\"\n",
        "\n",
        "# Invoke the chain to generate answers\n",
        "result = rag_chain.invoke(question)\n",
        "\n",
        "# Display the output\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o4mfFds9Xfwp",
        "outputId": "606ce901-cde1-4a76-a971-3022d64622d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a professional AI researcher, give an help in study. Use the following context to answer the question using information provided by the paper:\n",
            "\n",
            "[Document(id='c6471a4b-9c42-46fa-8800-e1c9641e8926', metadata={'source': './2501.12948v1.pdf', 'page': 4, 'page_label': '5'}, page_content='the inclusion of a small amount of cold-start data. In the following sections, we present: (1)\\nDeepSeek-R1-Zero, which applies RL directly to the base model without any SFT data, and\\n(2) DeepSeek-R1, which applies RL starting from a checkpoint fine-tuned with thousands of\\nlong Chain-of-Thought (CoT) examples. 3) Distill the reasoning capability from DeepSeek-R1 to\\nsmall dense models.\\n2.2. DeepSeek-R1-Zero: Reinforcement Learning on the Base Model'), Document(id='47ec7b12-9b93-49b2-a957-1d74f702f136', metadata={'source': './2501.12948v1.pdf', 'page': 3, 'page_label': '4'}, page_content='1.1. Contributions\\nPost-Training: Large-Scale Reinforcement Learning on the Base Model\\nâ€¢ We directly apply RL to the base model without relying on supervised fine-tuning (SFT) as\\na preliminary step. This approach allows the model to explore chain-of-thought (CoT) for\\nsolving complex problems, resulting in the development of DeepSeek-R1-Zero. DeepSeek-\\nR1-Zero demonstrates capabilities such as self-verification, reflection, and generating'), Document(id='fddce56b-eeda-4301-9bd0-bc76185d617d', metadata={'source': './2501.12948v1.pdf', 'page': 0, 'page_label': '1'}, page_content='DeepSeek-R1: Incentivizing Reasoning Capability in LLMs via\\nReinforcement Learning\\nDeepSeek-AI\\nresearch@deepseek.com\\nAbstract\\nWe introduce our first-generation reasoning models, DeepSeek-R1-Zero and DeepSeek-R1.\\nDeepSeek-R1-Zero, a model trained via large-scale reinforcement learning (RL) without super-\\nvised fine-tuning (SFT) as a preliminary step, demonstrates remarkable reasoning capabilities.\\nThrough RL, DeepSeek-R1-Zero naturally emerges with numerous powerful and intriguing')]\n",
            "\n",
            "Question: What are the advantages of using reinforcement learning directly on a base model, as demonstrated by DeepSeek-R1-Zero?\n",
            "</think>\n",
            "\n",
            "The advantages of using reinforcement learning directly on a base model, as exemplified by DeepSeek-R1-Zero, include:\n",
            "\n",
            "1. **Direct Application of RL**: DeepSeek-R1-Zero showcases the effectiveness of applying reinforcement learning directly to the base model without prior supervised fine-tuning.\n",
            "\n",
            "2. **Chain-of-Thought (CoT) Utilization**: The model leverages CoT techniques inherently during its training process through reinforcement learning.\n",
            "\n",
            "3. **Enhanced Problem Solving Capabilities**: By integrating RL into the base model, DeepSeek-R1-Zero demonstrates improved performance in solving complex tasks through exploration and refinement.\n",
            "\n",
            "These features highlight how direct RL application can enhance a model's reasoning and problem-solving abilities effectively.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is cold-start data and why is it used in DeepSeek-R1 training?\"\n",
        "\n",
        "# Invoke the chain to generate answers\n",
        "result = rag_chain.invoke(question)\n",
        "\n",
        "# Display the output\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ftG7e2D2yjZc",
        "outputId": "45cab166-ebe2-4f1d-92d3-099478348ab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a professional AI researcher, give an help in study. Use the following context to answer the question using information provided by the paper:\n",
            "\n",
            "[Document(id='6154be67-45be-4a07-87f7-2ee0fde4236f', metadata={'source': './2501.12948v1.pdf', 'page': 8, 'page_label': '9'}, page_content='models to generate detailed answers with reflection and verification, gathering DeepSeek-R1-\\nZero outputs in a readable format, and refining the results through post-processing by human\\nannotators.\\nIn this work, we collect thousands of cold-start data to fine-tune the DeepSeek-V3-Base as\\nthe starting point for RL. Compared to DeepSeek-R1-Zero, the advantages of cold start data\\n9'), Document(id='4505bf93-bd96-4a96-9bf8-a8e99c283b80', metadata={'source': './2501.12948v1.pdf', 'page': 15, 'page_label': '16'}, page_content='learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start\\ndata, achieving strong performance across various tasks. DeepSeek-R1 is more powerful,\\nleveraging cold-start data alongside iterative RL fine-tuning. Ultimately, DeepSeek-R1 achieves\\nperformance comparable to OpenAI-o1-1217 on a range of tasks.\\nWe further explore distillation the reasoning capability to small dense models. We use'), Document(id='c6471a4b-9c42-46fa-8800-e1c9641e8926', metadata={'source': './2501.12948v1.pdf', 'page': 4, 'page_label': '5'}, page_content='the inclusion of a small amount of cold-start data. In the following sections, we present: (1)\\nDeepSeek-R1-Zero, which applies RL directly to the base model without any SFT data, and\\n(2) DeepSeek-R1, which applies RL starting from a checkpoint fine-tuned with thousands of\\nlong Chain-of-Thought (CoT) examples. 3) Distill the reasoning capability from DeepSeek-R1 to\\nsmall dense models.\\n2.2. DeepSeek-R1-Zero: Reinforcement Learning on the Base Model')]\n",
            "\n",
            "Question: What is cold-start data and why is it used in DeepSeek-R1 training?\n",
            "</think>\n",
            "\n",
            "Cold-start data refers to initial training data that is not yet available or relevant to the target task. It's commonly used in scenarios where there's limited prior knowledge about the task at hand.\n",
            "\n",
            "In the context of DeepSeek-R1 training:\n",
            "- Cold-start data helps initialize the model effectively.\n",
            "- It enables the model to learn foundational patterns or representations needed for subsequent tasks.\n",
            "- By leveraging cold-start data, the model can gradually adapt and improve its performance over time.\n",
            "\n",
            "Thus, cold-start data plays a crucial role in enabling effective learning and adaptation during training.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What are DeepSeek-R1-Zero and DeepSeek-R1?\"\n",
        "\n",
        "# Invoke the chain to generate answers\n",
        "result = rag_chain.invoke(question)\n",
        "\n",
        "# Display the output\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6za7eriy1mV",
        "outputId": "47d6be32-578a-4a93-a6c4-2e4646b455f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are a professional AI researcher, give an help in study. Use the following context to answer the question using information provided by the paper:\n",
            "\n",
            "[Document(id='4505bf93-bd96-4a96-9bf8-a8e99c283b80', metadata={'source': './2501.12948v1.pdf', 'page': 15, 'page_label': '16'}, page_content='learning. DeepSeek-R1-Zero represents a pure RL approach without relying on cold-start\\ndata, achieving strong performance across various tasks. DeepSeek-R1 is more powerful,\\nleveraging cold-start data alongside iterative RL fine-tuning. Ultimately, DeepSeek-R1 achieves\\nperformance comparable to OpenAI-o1-1217 on a range of tasks.\\nWe further explore distillation the reasoning capability to small dense models. We use'), Document(id='9dd48cae-8619-445f-a962-e393bb52a1a8', metadata={'source': './2501.12948v1.pdf', 'page': 7, 'page_label': '8'}, page_content='Figure 3 |The average response length of DeepSeek-R1-Zero on the training set during the RL\\nprocess. DeepSeek-R1-Zero naturally learns to solve reasoning tasks with more thinking time.\\nment throughout the training process. This improvement is not the result of external adjustments\\nbut rather an intrinsic development within the model. DeepSeek-R1-Zero naturally acquires the\\nability to solve increasingly complex reasoning tasks by leveraging extended test-time compu-'), Document(id='c454e456-e97f-40ae-9b4d-edfaea23b0cf', metadata={'source': './2501.12948v1.pdf', 'page': 0, 'page_label': '1'}, page_content='Figure 1 |Benchmark performance of DeepSeek-R1.\\narXiv:2501.12948v1  [cs.CL]  22 Jan 2025')]\n",
            "\n",
            "Question: What are DeepSeek-R1-Zero and DeepSeek-R1?\n",
            "</think>\n",
            "\n",
            "DeepSeek-R1-Zero and DeepSeek-R1 are both advanced AI models developed by DeepSeek. Here's a comparison between them:\n",
            "\n",
            "1. **DeepSeek-R1**:\n",
            "   - **Source**: The source document is `./2501.12948v1.pdf`.\n",
            "   - **Page Content**: \n",
            "     - It leverages cold-start data for its initial performance.\n",
            "     - It uses iterative RL fine-tuning to enhance its capabilities.\n",
            "     - Its final performance matches that of OpenAI's o1-1217 on various tasks.\n",
            "\n",
            "2. **DeepSeek-R1-Zero**:\n",
            "   - **Source**: The source document is also `./2501.12948v1.pdf`.\n",
            "   - **Page Content**: \n",
            "     - It represents a pure RL approach without reliance on cold-start data.\n",
            "     - It achieves strong performance across various tasks independently.\n",
            "     - It demonstrates better performance than DeepSeek-R1 through iterative RL fine-tuning.\n",
            "\n",
            "In summary, while both models are based on RL (Reinforcement Learning), DeepSeek-R1-Zero operates independently, whereas DeepSeek-R1 utilizes cold-start data.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}